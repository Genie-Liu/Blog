# CTR预估模型之DeepFM

2016年google推出了wide&deep模型之后，基本上就成为了各大推荐系统的标配。该模型既能
学习到低阶的记忆性，又能学习到高阶部分的泛化性，所以整体效果来说是比较好的。

但是它有个麻烦的地方，那就是wide部分需要较多的特征工程工作。这一点对于人员紧张的
小厂来说还是不太方便。而FM具有自动学习交叉特征的能力，同时其使用的隐变量也可以跟
Deep部分一起共享。所以也就有了DeepFM这个模型，用FM来代替wide部分。

## FM简单介绍

FM模型把稀疏特征映射为K维的隐变量，并且通过隐变量之间的点积来作为两个特征交叉的权重值.
当然FM也可以做高阶的特征交叉，但是绝大部分时候我们还是只用二阶部分，更高阶的部分我们经常是用深度模型来做。

整体来看FM解决了两个问题：

* 使用特征隐变量内积来模拟两个特征的交叉权重。

    假如我们有n个特征，则二阶交叉有$n x n$种可能，所以需要训练$n x n$个参数。通过隐变量的方式，我们只需要训练$k x n$个参数
    
* 降低交叉特征的计算复杂度。

    通过对矩阵计算的转化，从原先的$k x n x n$复杂度降为 $k x n$
    
对比FM和Wide&Deep的Wide部分：

优点：

* 无需特征工程，这一点对于搭建端到端模型来说还是比较重要的。
* 通过隐变量计算交叉特征权重，所以不需要交叉特征共同出现在样本，只要各自都出现过就行。

缺点：

* 可解释性不如wide
* 计算高阶交叉时需要对全员做交叉，wide则可以通过特征工程选择部分交叉特征

## DeepFM

尽管FM

参考资料：
1 [DeepFM: A Factorization-Machine based Neural Network for CTR Prediction](https://arxiv.org/abs/1703.04247)
